# Driver Gaze Detection in Static and Moving Vehicles

## Overview
Driver Gaze Detection in Static and Moving Vehicles is my Undergraduate project aimed at developing a comprehensive system for monitoring and analyzing driver gaze behavior in varying driving conditions. The project utilizes the Pupil Invisible Eye tracker device in conjunction with installed cameras to capture eye movements and head positions of drivers within vehicles. The primary objective is to differentiate between driver gaze patterns in static environments and while driving.

## Objective
The main goal of this project is to enhance the understanding of driver gaze behavior and its implications in different driving conditions. Specifically, the project aims to:

- Develop algorithms for detecting and tracking driver gaze movements across designated windshield zones.
- Compare and analyze driver gaze patterns between static and driving scenarios.
- Evaluate the effectiveness and accuracy of the gaze detection system through rigorous testing and validation processes.
- Explore potential applications for improving the safety and efficiency of autonomous vehicles, driver fatigue detection systems and human-computer interaction interfaces.

## Key Components
### Hardware
- Pupil Invisible Eye tracker device
- Cameras installed within the vehicle for head position tracking

### Software and Libraries
- Python: Programming language used for algorithm development and implementation
- OpenCV: Library for image processing and computer vision tasks
- Tools: Jupyter Notebook and Google Colab
<!-- - TensorFlow: Deep learning framework for advanced feature extraction and classification -->
<!-- - Matplotlib and Plotly: Libraries for data visualization and analysis -->
- Various machine learning and statistical analysis tools for model evaluation and validation

## Technical Details
- Iris region detection and positional tracking algorithms implemented using OpenCV.
- Utilization of ground truth comparisons and manual annotations for model validation and refinement.
- Integration of machine learning algorithms for real-time analysis of driver gaze behavior.
<!-- - Development of a user-friendly interface for data visualization and analysis using Matplotlib and Plotly. -->
- Continuous improvement of model accuracy through data augmentation techniques and algorithmic enhancements.

## Currently Working On:
- Improvement of image processing algorithms for Iris detection.
- Synchronizing the iris position data and the gaze of the driver at that point of time.

<!-- ## Usage
To use the Driver Gaze Detection system:
1. Install the required dependencies using the provided `requirements.txt` file.
2. Connect the Pupil Invisible Eye tracker device and ensure proper camera calibration.
3. Run the main Python script to start the gaze detection system.
4. Follow the instructions for data collection and analysis provided in the documentation. -->

## Contributions and Feedback
Contributions to the project are welcome via pull requests. For feedback, questions, or suggestions, please open an issue on the GitHub repository.

<!-- ## License -->
<!-- This project is licensed under the MIT License. See the LICENSE file for details. -->
