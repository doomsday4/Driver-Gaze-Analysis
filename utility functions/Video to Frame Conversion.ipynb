{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video to frame conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vidcap = cv2.VideoCapture(\"path to the video\")\n",
    "\n",
    "success,image = vidcap.read()\n",
    "count = 1\n",
    "while success:\n",
    "    cv2.imwrite(\"/path to the folder/%d.jpg\" % count, image) # save frame as JPEG file\n",
    "    success,image = vidcap.read()\n",
    "    print('Read a new frame: ', success)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Frame-Rate Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "video_file = \"path to the video\"\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture(video_file)\n",
    "\n",
    "# Set the current frame rate\n",
    "current_fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(current_fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video to frame conversion using frame rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#Define the video file path\n",
    "video_path = \"path to the video\"\n",
    "output_path = \"path to the folder where output needs to be added\"\n",
    "\n",
    "# Define the desired frame rate for extraction\n",
    "frame_rate = 18000  # For example, extracting every 2 seconds\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the frames per second (fps) of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Calculate the frame interval based on desired frame rate\n",
    "frame_interval = int(fps / frame_rate)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Break the loop if no more frames are available\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract frames at the desired frame rate\n",
    "    if frame_count % frame_interval == 0:\n",
    "        # Save or process the extracted frame here\n",
    "        frame_filename = output_path+f'frame{frame_count}.jpg'\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "input_file = \"E:/Driver_Gaze_Data/P220230511D1/Eyetracker_Data/pupil-cloud-download-2024-01-14T14-00-29.489121-1-recordings/2023-05-11_16-06-01-e9ea58dd/PI right v1 ps1.mp4\"\n",
    "output_file = \"E:/Driver_Gaze_Data/P220230511D1/Eyetracker_Data/pupil-cloud-download-2024-01-14T14-00-29.489121-1-recordings/2023-05-11_16-06-01-e9ea58dd/P2_PI right v1 ps1.mp4\"\n",
    "start_time_minutes = 4   # Start time in minutes\n",
    "start_time_seconds = 27.5  # Start time in seconds\n",
    "duration_seconds = 60     # Duration in seconds\n",
    "\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "start_time_total_seconds = start_time_minutes * 60 + start_time_seconds\n",
    "start_frame = int(start_time_total_seconds * frame_rate)\n",
    "end_frame = start_frame + int(duration_seconds * frame_rate)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_file, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "for frame_index in range(start_frame, end_frame):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame Extraction with fixed frame rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_frames(video_path, output_folder, frame_rate):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Calculate the desired frame interval based on the fixed frame rate\n",
    "    interval = int(fps / frame_rate)\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    import os\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through frames and extract based on the frame rate\n",
    "    for i in range(0, total_frames, interval):\n",
    "        # Set the frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "\n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Save the frame to the output folder\n",
    "        if ret:\n",
    "            frame_filename = f\"{output_folder}/frame_{i:01d}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            print(f\"Frame {i} saved as {frame_filename}\")\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'input_video.mp4' with the path to your input video file\n",
    "    input_video_path = 'C:/Users/Pavan Kumar Sharma/Downloads/pupil-cloud-download-2024-01-05T06-07-56.675903-1-recordings/2023-05-11_16-46-45-273bb776/PI right v1 ps1.mp4'\n",
    "\n",
    "    # Replace 'output_frames' with the desired output folder\n",
    "    output_folder = 'C:/Users/Pavan Kumar Sharma/Downloads/pupil-cloud-download-2024-01-05T06-07-56.675903-1-recordings/2023-05-11_16-46-45-273bb776/Right_Eye_Frames'\n",
    "\n",
    "    # Replace 2 with your desired fixed frame rate (frames per second)\n",
    "    fixed_frame_rate = 20\n",
    "\n",
    "    # Call the function to extract frames\n",
    "    extract_frames(input_video_path, output_folder, fixed_frame_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder, frame_rate):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Calculate the desired frame interval based on the fixed frame rate\n",
    "    interval = int(fps / frame_rate)\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through frames and extract based on the frame rate\n",
    "    frame_count = 1\n",
    "    for i in range(0, total_frames, interval):\n",
    "        # Set the frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "\n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Save the frame to the output folder\n",
    "        if ret:\n",
    "            frame_filename = f\"{output_folder}/frame{frame_count:1d}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            print(f\"Frame {frame_count} saved as {frame_filename}\")\n",
    "            frame_count += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'input_video.mp4' with the path to your input video file\n",
    "    input_video_path = 'C:/Users/Pavan Kumar Sharma/Downloads/pupil-cloud-download-2024-01-05T06-07-56.675903-1-recordings/2023-05-11_16-46-45-273bb776/PI left v1 ps1.mp4'\n",
    "    # Replace 'output_frames' with the desired output folder\n",
    "    output_folder = 'C:/Users/Pavan Kumar Sharma/Downloads/pupil-cloud-download-2024-01-05T06-07-56.675903-1-recordings/2023-05-11_16-46-45-273bb776/Left_Eye_Frames'\n",
    "\n",
    "    # Replace 2 with your desired fixed frame rate (frames per second)\n",
    "    fixed_frame_rate = 20\n",
    "\n",
    "    # Call the function to extract frames\n",
    "    extract_frames(input_video_path, output_folder, fixed_frame_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frames rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def rotate_frames(input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Read the image\n",
    "        frame = cv2.imread(input_path)\n",
    "\n",
    "        if frame is not None:\n",
    "            # Rotate the frame by 270 degrees\n",
    "            rotated_frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "            # Save the rotated frame to the output folder\n",
    "            cv2.imwrite(output_path, rotated_frame)\n",
    "            print(f\"Rotated and saved: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"/Users/apple/Downloads/Sem6/ugp/output/eye1/\"\n",
    "    output_folder = \"/Users/apple/Downloads/Sem6/ugp/output/eye1_rotated/\"\n",
    "\n",
    "    rotate_frames(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_video_length(file_path):\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = frame_count / fps\n",
    "        cap.release()\n",
    "        return duration\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Replace 'your_video_file.mp4' with the path to your video file\n",
    "video_path = 'E:/Driver_Gaze_Data/P220230511D1/Eyetracker_Data/pupil-cloud-download-2024-01-14T14-00-29.489121-1-recordings/2023-05-11_16-06-01-e9ea58dd/PI right v1 ps1.mp4'\n",
    "\n",
    "length = get_video_length(video_path)\n",
    "\n",
    "if length is not None:\n",
    "    print(f\"The length of the video is: {length} seconds\")\n",
    "else:\n",
    "    print(\"Unable to determine the length of the video.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frame from fixed time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_frames(video_path, output_path, start_time, interval, duration):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open the video file.\")\n",
    "        return\n",
    "\n",
    "    # Set the start time\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret or frame_count * interval > duration:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Save the frame\n",
    "        output_frame_path = f\"{output_path}/frame{frame_count}.jpg\"\n",
    "        cv2.imwrite(output_frame_path, frame)\n",
    "\n",
    "        # Move to the next frame\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, (start_time + frame_count * interval) * 1000)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"E:/Driver_Gaze_Data/P220230511D1/Eyetracker_Data/pupil-cloud-download-2024-01-14T14-00-29.489121-1-recordings/2023-05-11_16-06-01-e9ea58dd/PI right v1 ps1.mp4\"\n",
    "    output_path = \"E:/Driver_Gaze_Data/P220230511D1/Eyetracker_Data/pupil-cloud-download-2024-01-14T14-00-29.489121-1-recordings/2023-05-11_16-06-01-e9ea58dd/Right\"\n",
    "    start_time = 267.5    # seconds\n",
    "    interval = 0.2       # seconds\n",
    "    duration = 60        # seconds (one minute)\n",
    "\n",
    "    extract_frames(video_path, output_path, start_time, interval, duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vidcap = cv2.VideoCapture('E:/Driver_Gaze_Data/P720230526D2/Exp/1683801340456800474_cam_1.mp4')\n",
    "#vidcap = cv2.VideoCapture('D:/Perungulathursection/DRONE03/DAY 1/MORNING/CARD 2 - 11.00 to 11.30/DJI_0001.MP4')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "    cv2.imwrite('E:/Driver_Gaze_Data_Processing/P720230526D2/Front_Camera_Frame/frame%d.jpg' % count, image) # save frame as JPEG file\n",
    "    success,image = vidcap.read()\n",
    "    print('Read a new frame: ', success)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Path to the first CSV file containing timestamps\n",
    "csv1_path = \"D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Ground_Truth_GAZE-OVERLAY_Ground_Truth_Generation/2023-05-11_16-46-45-273bb776/world_timestamps(UTC).csv\"\n",
    "\n",
    "# Path to the second CSV file containing timestamps and frame IDs\n",
    "csv2_path = \"D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Exp1/Cam_1_Frame/Time_Stamps(UTC) Cam_1_Frame.csv\"\n",
    "\n",
    "\n",
    "# Path to the folder containing the video frames\n",
    "frames_folder = \"D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Exp1/Cam_1_Frame/\"\n",
    "\n",
    "# Path to the destination folder to copy matching frames\n",
    "destination_folder = \"D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Exp1/Cam1/\"\n",
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "csv1_data = pd.read_csv(csv1_path)\n",
    "csv2_data = pd.read_csv(csv2_path)\n",
    "\n",
    "# Iterate over each row in the first CSV file\n",
    "for _, row_csv1 in csv1_data.iterrows():\n",
    "    timestamp_csv1 = datetime.strptime(row_csv1['IST Time'], '%Y-%m-%d %H:%M:%S.%f%z')\n",
    "\n",
    "    # Find the nearest matching timestamp in the second CSV file\n",
    "    closest_frame = None\n",
    "    closest_time_diff = float('inf')\n",
    "\n",
    "    for _, row_csv2 in csv2_data.iterrows():\n",
    "        timestamp_csv2 = datetime.strptime(row_csv2['IST Time'], '%Y-%m-%d %H:%M:%S.%f%z')\n",
    "        time_diff = abs(timestamp_csv1 - timestamp_csv2)\n",
    "\n",
    "        if time_diff < closest_time_diff:\n",
    "            closest_time_diff = time_diff\n",
    "            closest_frame = row_csv2['Frame_ID']\n",
    "\n",
    "    if closest_frame is not None:\n",
    "        # Construct the frame filename based on the frame ID\n",
    "        frame_filename =  str(closest_frame) + '.jpg'\n",
    "\n",
    "        # Source path of the matching frame\n",
    "        source_frame_path = os.path.join(frames_folder, frame_filename)\n",
    "\n",
    "        # Destination path to copy the matching frame\n",
    "        destination_frame_path = os.path.join(destination_folder, frame_filename)\n",
    "\n",
    "        # Copy the matching frame to the destination folder\n",
    "        shutil.copyfile(source_frame_path, destination_frame_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Read the first CSV file with UTC timestamps\n",
    "df_timestamps = pd.read_csv(\"D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Ground_Truth_GAZE-OVERLAY_Ground_Truth_Generation/2023-05-11_16-46-45-273bb776/world_timestamps(UTC).csv\")\n",
    "\n",
    "\n",
    "# Step 2: Read the second CSV file with frame IDs and timestamps\n",
    "df_frames = pd.read_csv(\"D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Exp1/Cam_1_Frame/Time_Stamps(UTC) Cam_1_Frame.csv\")\n",
    "\n",
    "# Step 3: Iterate over each row in the first DataFrame\n",
    "for index, row in df_timestamps.iterrows():\n",
    "    target_timestamp = datetime.strptime(row['IST Time'], '%Y-%m-%d %H:%M:%S.%f%z')\n",
    "\n",
    "    # Step 4: Find the nearest timestamp in the second DataFrame\n",
    "    nearest_timestamp = df_frames['IST Time'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f%z')).\\\n",
    "        iloc[(df_frames['IST Time'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f%z')) - target_timestamp).abs().idxmin()]\n",
    "    \n",
    "    # Step 5: Retrieve the corresponding frame ID and move the frame file to a new folder\n",
    "    frame_id = df_frames.loc[df_frames['timestamp'] == nearest_timestamp, 'frame_id'].values[0]\n",
    "    frame_file = f'{frame_id}.jpg'  # Assuming frames are in JPG format\n",
    "    source_path = f'D:\\Academics\\PHD Admission\\IIT Kanpur\\Data Collection\\Driver_Face\\Driver_Gaze_Data\\P320230511\\Exp1\\Cam_1_Frame/{frame_file}'  # Update with the actual source folder path\n",
    "    destination_folder = f'D:\\Academics\\PHD Admission\\IIT Kanpur\\Data Collection\\Driver_Face\\Driver_Gaze_Data\\P320230511\\Exp1\\Cam1/{frame_id}'  # Update with the destination folder path\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    destination_path = f'{destination_folder}/{frame_file}'\n",
    "    os.rename(source_path, destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Read the first CSV file with UTC timestamps\n",
    "df_timestamps = pd.read_csv(\"D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Ground_Truth_GAZE-OVERLAY_Ground_Truth_Generation/2023-05-11_16-46-45-273bb776/world_timestamps(UTC).csv\")\n",
    "\n",
    "\n",
    "# Step 2: Read the second CSV file with frame IDs and timestamps\n",
    "df_frames = pd.read_csv(\"D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Exp1/Cam_1_Frame/Time_Stamps(UTC) Cam_1_Frame.csv\")\n",
    "\n",
    "# Step 3: Iterate over each row in the first DataFrame\n",
    "for index, row in df_timestamps.iterrows():\n",
    "    target_timestamp = datetime.strptime(row['IST Time'], '%Y-%m-%d %H:%M:%S.%f%z')\n",
    "\n",
    "    # Step 4: Find the nearest timestamp in the second DataFrame\n",
    "    nearest_timestamp = df_frames['IST Time'].apply(lambda x: datetime.strptime(x.replace(':', ''), '%Y-%m-%d %H:%M:%S.%f%z')).\\\n",
    "        iloc[(df_frames['IST Time'].apply(lambda x: datetime.strptime(x.replace(':', ''), '%Y-%m-%d %H:%M:%S.%f%z')) - target_timestamp).abs().idxmin()]\n",
    "    \n",
    "    # Step 5: Retrieve the corresponding frame ID and move the frame file to a new folder\n",
    "    frame_id = df_frames.loc[df_frames['timestamp'] == nearest_timestamp, 'frame_id'].values[0]\n",
    "    frame_file = f'{frame_id}.jpg'  # Assuming frames are in JPG format\n",
    "    source_path = f'D:\\Academics\\PHD Admission\\IIT Kanpur\\Data Collection\\Driver_Face\\Driver_Gaze_Data\\P320230511\\Exp1\\Cam_1_Frame/{frame_file}'  # Update with the actual source folder path\n",
    "    destination_folder = f'D:\\Academics\\PHD Admission\\IIT Kanpur\\Data Collection\\Driver_Face\\Driver_Gaze_Data\\P320230511\\Exp1\\Cam1/{frame_id}'  # Update with the destination folder path\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    destination_path = f'{destination_folder}/{frame_file}'\n",
    "    os.rename(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Exp1/Time_Stamps(UTC) Cam_1_Frame.csv')\n",
    "\n",
    "# Remove the timezone offset from the timestamp column\n",
    "df['IST Time'] = df['IST Time'].str.replace(r'\\+\\d{2}:\\d{2}$', '', regex=True)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(df)\n",
    "# Convert the timestamp column to string\n",
    "df['IST Time'] = df['IST Time'].astype(str)\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('D:/Academics/PHD Admission/IIT Kanpur/Data Collection/Driver_Face/Driver_Gaze_Data/P320230511/Exp1/Time_Stamps(UTC) Cam_1_Frame(new).csv', index=False, float_format='%.9f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "timestamp = '2023-05-11 16:46:39.190953178+05:30'\n",
    "datetime_obj = datetime.datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S.%f%z')\n",
    "epoch = int(datetime_obj.timestamp())\n",
    "\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "timestamp = '2023-05-11 16:46:39.390953178+05:30'\n",
    "timestamp_without_microsec = timestamp.split('.')[0]  # Remove microseconds\n",
    "timestamp_without_offset = timestamp_without_microsec.rsplit('+', 1)[0]  # Remove timezone offset\n",
    "datetime_obj = datetime.datetime.strptime(timestamp_without_offset, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "epoch = int(datetime_obj.timestamp() * 1e9)\n",
    "\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_frames(video_path):\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_rate = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Set the initial frame count and timestamp\n",
    "    frame_count = 0\n",
    "    timestamp = 0\n",
    "\n",
    "    while True:\n",
    "        # Read the next frame\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Check if it's time to extract a frame\n",
    "        if frame_count % int(frame_rate) == 0:\n",
    "            # Save the frame with the corresponding timestamp\n",
    "            frame_name = f\"{timestamp}.jpg\"\n",
    "            cv2.imwrite(frame_name, frame)\n",
    "            print(f\"Saved frame: {frame_name}\")\n",
    "\n",
    "        # Increment the frame count and timestamp\n",
    "        frame_count += 1\n",
    "        timestamp += 1\n",
    "\n",
    "    # Release the video file\n",
    "    video.release()\n",
    "\n",
    "# Example usage\n",
    "video_path = \"E:/Driver_Gaze_Data/P420230526D2/Eyetracker_Data/2023-05-26_10-45-19-8e15fb3e/4a276385_0.0-682.736.mp4\"\n",
    "extract_frames(video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge multiple CSV file into single CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "  \n",
    "# merging the files\n",
    "joined_files = os.path.join(\"E:/Driver_Gaze_Data_Processing/gt_speak_Merge\", \"gt_speak_merge*.csv\")\n",
    "  \n",
    "# A list of all joined files is returned\n",
    "joined_list = glob.glob(joined_files)\n",
    "  \n",
    "# Finally, the files are joined\n",
    "df = pd.concat(map(pd.read_csv, joined_list), ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "  \n",
    "# merging the files\n",
    "joined_files = os.path.join(\"E:/Driver_Gaze_Data_Processing/Manual_Annotation/Manual Annotation(Two Annotator)\", \"P*.csv\")\n",
    "  \n",
    "# A list of all joined files is returned\n",
    "joined_list = glob.glob(joined_files)\n",
    "  \n",
    "# Finally, the files are joined\n",
    "df = pd.concat(map(pd.read_csv, joined_list), ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('E:/Driver_Gaze_Data_Processing/Manual_Annotation/Manual Annotation(Two Annotator)/merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:/Driver_Gaze_Data_Processing/gt_speak_Merge/merge.csv\")\n",
    "#df.drop(['remove'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/merge1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Speak_File', 'Org_Speak_Class', 'Speak_Class', 'Speak_Class_Counter'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GT_File', 'Frame', 'Speak_File'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/Gt_merge_confusion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_color_gradients('Perceptually Uniform Sequential',\n",
    "                     ['viridis', 'plasma', 'inferno', 'magma', 'cividis'])\n",
    "\n",
    "plot_color_gradients('Sequential',\n",
    "                     ['Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',\n",
    "                      'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n",
    "                      'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for moving pointer based method\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "# Define custom colors\n",
    "custom_colors = ['#FF5733', '#33FF57', '#3366FF', '#FF33CC']  # Add more colors as needed\n",
    "\n",
    "# Create a custom colormap\n",
    "custom_cmap = mcolors.ListedColormap(custom_colors)\n",
    "\n",
    "data= pd.read_csv(\"E:/Driver_Gaze_Data_Processing/Moving_Pointer/Moving_Pointer_Frame_Wise/CSV_File/MP_Frame_P4320230528D4.csv\")\n",
    "confusion_matrix = pd.crosstab(data['GT_Class'], data['Pointer_Class'], rownames=['Ground_Truth_Class'], colnames=['Pointer_Class'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Oranges', fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Pointer_Class')\n",
    "plt.ylabel('Ground_Truth_Class')\n",
    "# Save the figure\n",
    "plt.savefig('E:/Driver_Gaze_Data_Processing/Moving_Pointer/Moving_Pointer_Frame_Wise/CSV_File/Accuracy Analysis/Confusion Matrix/MP_Confusion_Matrix_P43.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "# Define custom colors\n",
    "custom_colors = ['#FF5733', '#33FF57', '#3366FF', '#FF33CC']  # Add more colors as needed\n",
    "\n",
    "# Create a custom colormap\n",
    "custom_cmap = mcolors.ListedColormap(custom_colors)\n",
    "\n",
    "data= pd.read_csv(\"E:/Driver_Gaze_Data_Processing/Speak2label_New/GT_Merge(P10_M0)/gt_speak_merge43(P10_M0).csv\")\n",
    "confusion_matrix = pd.crosstab(data['GT_Class'], data['Speak_Class'], rownames=['Ground_Truth_Class'], colnames=['Speak_Class'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Oranges', fmt='d')\n",
    "plt.title('Confusion Matrix_(P10_M0)')\n",
    "plt.xlabel('Speak_Class')\n",
    "plt.ylabel('Ground_Truth_Class')\n",
    "# Save the figure\n",
    "plt.savefig('E:/Driver_Gaze_Data_Processing/Speak2label_New/Accuracy_Calculation/Analysis of P10_M/Confusion_Matrix_(P10_M0)_P43.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "# Define custom colors\n",
    "custom_colors = ['#FF5733', '#33FF57', '#3366FF', '#FF33CC']  # Add more colors as needed\n",
    "\n",
    "# Create a custom colormap\n",
    "custom_cmap = mcolors.ListedColormap(custom_colors)\n",
    "\n",
    "data= pd.read_csv('E:/Driver_Gaze_Data_Processing/Manual_Annotation/Frame_wise_Manual_Annotation/Frame_Wise_Manual_Annotation.csv')\n",
    "confusion_matrix = pd.crosstab(data['GT_Class'], data['Annotated_Class'], rownames=['Ground_Truth_Class'], colnames=['Annotated_Class'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Oranges', fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Annotated_Class')\n",
    "plt.ylabel('Ground_Truth_Class')\n",
    "# Save the figure\n",
    "plt.savefig('E:/Driver_Gaze_Data_Processing/Manual_Annotation/Frame_wise_Manual_Annotation/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "# Define custom colors\n",
    "custom_colors = ['#FF5733', '#33FF57', '#3366FF', '#FF33CC']  # Add more colors as needed\n",
    "\n",
    "# Create a custom colormap\n",
    "custom_cmap = mcolors.ListedColormap(custom_colors)\n",
    "\n",
    "data= pd.read_csv(\"E:/Driver_Gaze_Data_Processing/Manual_Annotation/Manual Annotation(Two Annotator)/P1920230527D3_Frame.csv\")\n",
    "confusion_matrix = pd.crosstab(data['GT_Class'], data['Class_A1'], rownames=['Ground_Truth_Class'], colnames=['Annotator_Class'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Oranges', fmt='d')\n",
    "plt.title('Confusion Matrix Annotator1 P19')\n",
    "plt.xlabel('Annotator_Class')\n",
    "plt.ylabel('Ground_Truth_Class')\n",
    "# Save the figure\n",
    "plt.savefig('E:/Driver_Gaze_Data_Processing/Manual_Annotation/Manual Annotation(Two Annotator)/Confusion_Matrix/MA_Confusion_Matrix_A1_P19.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "data = pd.read_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/merge1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['GT_File', 'Frame', 'Speak_File', 'Org_Speak_Class', 'Speak_Class_Counter', 'Frame_ID'], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/max_frequency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/max_frequency.csv')\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(len(df)):\n",
    "    if pd.isnull(df.at[i, 'Speak_Class']):  # Check if the cell is empty\n",
    "        # Calculate the range of rows to consider above and below the empty cell\n",
    "        start_idx = max(0, i - 10)\n",
    "        end_idx = min(len(df), i + 11)\n",
    "        \n",
    "        # Get non-empty values in the range\n",
    "        valid_values = df.loc[start_idx:end_idx, 'Speak_Class'].dropna()\n",
    "        \n",
    "        # If there are valid values, fill the empty cell\n",
    "        if not valid_values.empty:\n",
    "            df.at[i, 'Speak_Class'] = valid_values.iloc[0]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/filled_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove missing value in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "df = pd.read_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/max_frequency(accuracy).csv')\n",
    "df.dropna(subset=['Speak_Class'], inplace = True)\n",
    "df.head()\n",
    "df.to_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/max_frequency(accuracy1).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find most common match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/max_frequency(accuracy1).csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('E:/Driver_Gaze_Data_Processing/gt_speak_Merge/max_frequency(accuracy1).csv')\n",
    "\n",
    "# Initialize variables to keep track of the current sequence\n",
    "current_sequence_value = None\n",
    "current_sequence_count = 0\n",
    "matching_count = 0\n",
    "non_matching_count = 0\n",
    "\n",
    "# Iterate through each row\n",
    "for index, row in df.iterrows():\n",
    "    column1_value = row['GT_Class']\n",
    "    column2_value = row['Speak_Class']\n",
    "    \n",
    "    if current_sequence_value is None:\n",
    "        current_sequence_value = column2_value\n",
    "        current_sequence_count = 1\n",
    "    elif column2_value == current_sequence_value:\n",
    "        current_sequence_count += 1\n",
    "    else:\n",
    "        # Compare column1_value with current_sequence_value\n",
    "        if column1_value == current_sequence_value:\n",
    "            matching_count += current_sequence_count\n",
    "        else:\n",
    "            non_matching_count += current_sequence_count\n",
    "        \n",
    "        current_sequence_value = column2_value\n",
    "        current_sequence_count = 1\n",
    "\n",
    "# Handle the last sequence\n",
    "if current_sequence_value is not None:\n",
    "    if column1_value == current_sequence_value:\n",
    "        matching_count += current_sequence_count\n",
    "    else:\n",
    "        non_matching_count += current_sequence_count\n",
    "\n",
    "# Determine which count is greater\n",
    "if matching_count >= non_matching_count:\n",
    "    print(f'Matching count is greater: {matching_count}')\n",
    "else:\n",
    "    print(f'Non-matching count is greater: {non_matching_count}')\n",
    "\n",
    "# Print the corresponding value from Column2\n",
    "print(f'Corresponding Column2 value: {current_sequence_value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# Read the input CSV file\n",
    "input_file = 'E:/Driver_Gaze_Data_Processing/gt_speak_Merge/max_frequency(accuracy1).csv'\n",
    "output_file = 'E:/Driver_Gaze_Data_Processing/gt_speak_Merge/output.csv'\n",
    "\n",
    "class_mapping = {}  # To store the mapping of class values to their corresponding max class in column 2\n",
    "\n",
    "# Read the CSV file and process the data\n",
    "with open(input_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Skip header row\n",
    "\n",
    "    current_class = None\n",
    "    current_counter = Counter()\n",
    "\n",
    "    for row in reader:\n",
    "        gt_class = int(row[0])\n",
    "        speak_class = int(row[1])\n",
    "\n",
    "        if gt_class != current_class:\n",
    "            if current_class is not None:\n",
    "                max_speak_class = current_counter.most_common(1)[0][0]\n",
    "                class_mapping[current_class] = max_speak_class\n",
    "                current_counter.clear()\n",
    "\n",
    "            current_class = gt_class\n",
    "\n",
    "        current_counter[speak_class] += 1\n",
    "\n",
    "    # Handle the last class\n",
    "    if current_class is not None:\n",
    "        max_speak_class = current_counter.most_common(1)[0][0]\n",
    "        class_mapping[current_class] = max_speak_class\n",
    "\n",
    "# Write the output to a new CSV file\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['GT_Class', 'Speak_Class'])\n",
    "\n",
    "    for gt_class, speak_class in class_mapping.items():\n",
    "        writer.writerow([gt_class, speak_class])\n",
    "\n",
    "print(\"Output CSV file written successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# Read the input CSV file\n",
    "input_file = 'E:/Driver_Gaze_Data_Processing/gt_speak_Merge/max_frequency(accuracy1).csv'\n",
    "output_file = 'E:/Driver_Gaze_Data_Processing/gt_speak_Merge/output.csv'\n",
    "\n",
    "class_mapping = {}  # To store the mapping of class values to their corresponding max class in column 2\n",
    "\n",
    "# Read the CSV file and process the data\n",
    "with open(input_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Skip header row\n",
    "\n",
    "    current_class = None\n",
    "    current_counter = Counter()\n",
    "\n",
    "    for row in reader:\n",
    "        try:\n",
    "            gt_class = int(row[0])\n",
    "        except ValueError:\n",
    "            continue  # Skip rows with non-numeric GT_Class\n",
    "        speak_class = int(row[1])\n",
    "\n",
    "        if gt_class != current_class:\n",
    "            if current_class is not None:\n",
    "                max_speak_class = current_counter.most_common(1)[0][0]\n",
    "                class_mapping[current_class] = max_speak_class\n",
    "                current_counter.clear()\n",
    "\n",
    "            current_class = gt_class\n",
    "\n",
    "        current_counter[speak_class] += 1\n",
    "\n",
    "    # Handle the last class\n",
    "    if current_class is not None:\n",
    "        max_speak_class = current_counter.most_common(1)[0][0]\n",
    "        class_mapping[current_class] = max_speak_class\n",
    "\n",
    "# Write the output to a new CSV file\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['GT_Class', 'Speak_Class'])\n",
    "\n",
    "    for gt_class, speak_class in class_mapping.items():\n",
    "        writer.writerow([gt_class, speak_class])\n",
    "\n",
    "print(\"Output CSV file written successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "# Define custom colors\n",
    "custom_colors = ['#FF5733', '#33FF57', '#3366FF', '#FF33CC']  # Add more colors as needed\n",
    "\n",
    "# Create a custom colormap\n",
    "custom_cmap = mcolors.ListedColormap(custom_colors)\n",
    "\n",
    "data= pd.read_csv(\"E:/Driver_Gaze_Data_Processing/P1820230527D3/Speak2Label/Discrete_Gaze_Classes_Eyetracker(20)/gt_speak_merge18(P0_M0).csv\")\n",
    "confusion_matrix = pd.crosstab(data['GT_Class'], data['Speak_Class'], rownames=['Ground_Truth_Class'], colnames=['Speak_Class'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Oranges', fmt='d')\n",
    "plt.title('Confusion Matrix_(P0_M0)_P18')\n",
    "plt.xlabel('Speak_Class')\n",
    "plt.ylabel('Ground_Truth_Class')\n",
    "# Save the figure\n",
    "plt.savefig('E:/Driver_Gaze_Data_Processing/P1820230527D3/Speak2Label/Discrete_Gaze_Classes_Eyetracker(20)/Confusion_Matrix_(P0_M0)_18.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
